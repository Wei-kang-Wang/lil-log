---
layout: post
comments: True
title: "NeRF&3DGS with few views"
date: 2024-12-27 01:09:00

---

<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---

CVPR2021的[pixelNeRF: Neural Radiance Fields from One or Few Images](https://alexyu.net/pixelnerf/), ICCV2023的[S-VolSDF: Sparse Multi-View Stereo Regularization of Neural Implicit Surfaces](https://hao-yu-wu.github.io/s-volsdf/), NeurIPS2023的[DäRF: Boosting Radiance Fields from Sparse Inputs with Monocular Depth Adaptation](https://github.com/cvlab-kaist/DaRF), ICCV2023的[SparseNeRF: Distilling Depth Ranking for Few-shot Novel View Synthesis](https://sparsenerf.github.io/), [InstantSplat: Sparse-view SfM-free Gaussian Splatting in Seconds](https://instantsplat.github.io/), CVPR2024的[DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization](https://fictionarry.github.io/DNGaussian/), CVPR2024的[ZeroRF: Sparse View 360° Reconstruction with Zero Pretraining](https://sarahweiii.github.io/zerorf/), CVPR2024的[Is Vanilla MLP in Neural Radiance Field Enough for Few-shot View Synthesis?](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhu_Is_Vanilla_MLP_in_Neural_Radiance_Field_Enough_for_Few-shot_CVPR_2024_paper.pdf), [ConsistentNeRF: Enhancing Neural Radiance Fields with 3D Consistency for Sparse View Synthesis](https://skhu101.github.io/ConsistentNeRF/), ACM Siggraph Asia 2024的[High-Quality 3D Object Reconstruction from Four Views with Gaussian Splatting](https://gaussianobject.github.io/), [Sparse-DeRF: Deblurred Neural Radiance Fields from Sparse View](https://dogyoonlee.github.io/sparsederf/), ECCV2024的[UpFusion: Novel View Diffusion from Unposed Sparse View Observations](https://upfusion3d.github.io/), [MomentsNeRF: Incorporating Orthogonal Moments in Convolutional Neural Networks for One or Few-Shot Neural Rendering](https://amughrabi.github.io/momentsnerf/), CVPR2024的[Global and Hierarchical Geometry Consistency Priors for Few-shot NeRFs in Indoor Scenes](https://github.com/XT5un/P2NeRF), NeurIPS2023的[PanoGRF: Generalizable Spherical Radiance Fields for Wide-baseline Panoramas](https://thucz.github.io/PanoGRF/), CVPR2024的[CVT-xRF: Contrastive In-Voxel Transformer for 3D Consistent Radiance Fields from Sparse Inputs](https://zhongyingji.github.io/CVT-xRF/), CVPR2024的[Learning with Unreliability: Fast Few-shot Voxel Radiance Fields with Relative Geometric Consistency](https://github.com/HKCLynn/ReVoRF), CVPR2024的[ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Image](https://kylesargent.github.io/zeronvs/), CVPR2022的[AutoRF: Learning 3D Object Radiance Fields From Single View Observations](https://github.com/skyhehe123/AutoRF-pytorch), ICML2023的[GeCoNeRF: Few-shot Neural Radiance Fields via Geometric Consistency](https://cvlab-kaist.github.io/GeCoNeRF/), ECCV2022的[PlaneFormers: From Sparse View Planes to 3D Reconstruction](https://samiragarwala.github.io/PlaneFormers/), TPAMI2022的[RGBDNeRF: Neural Radiance Fields from Sparse RGB-D Images for High-Quality View Synthesis](http://geometrylearning.com/rgbdnerf/), ACM SIGGRAPH 2023的[Live 3D Portrait: Real-Time Radiance Fields for Single-Image Portrait View Synthesis](https://research.nvidia.com/labs/nxp/lp3d/), NeurIPS2022的[S3-NeRF: Neural Reflectance Field from Shading and Shadow under a Single Viewpoint](https://ywq.github.io/s3nerf/), ACM SIGGRAPH Asia 2023的[SimpleNeRF: Regularizing Sparse Input Neural Radiance Fields with Simpler Solutions](https://nagabhushansn95.github.io/publications/2023/SimpleNeRF.html), ACN SIGGRAPH 2023的[ViP-NeRF: Visibility Prior for Sparse Input Neural Radiance Fields](https://github.com/NagabhushanSN95/ViP-NeRF), ICLR2024的[LEAP: Liberate Sparse-view 3D Modeling
from Camera Poses](https://hwjiang1510.github.io/LEAP/), [ConsistentNeRF: Enhancing Neural Radiance Fields with 3D Consistency for Sparse View Synthesis](https://skhu101.github.io/ConsistentNeRF/), NeurrIPS2023的[DreamSparse: Escaping from Plato’s Cave with 2D Frozen Diffusion Model given Sparse Views](https://sites.google.com/view/dreamsparse-webpage), ACM SIGGRAPH Asia 2023的[ReShader: View-Dependent Highlights for Single Image View-Synthesis](https://github.com/avinashpaliwal/ReShader), CVPR2024的[MultiDiff: Consistent Novel View Synthesis from a Single Image](https://sirwyver.github.io/MultiDiff/), [LiftRefine: Progressively Refined View Synthesis from 3D Lifting with Volume-Triplane Representations](https://arxiv.org/pdf/2412.14464), ECCV2022的[ViewFormer: NeRF-free Neural Rendering from Few Images Using Transformers](https://jkulhanek.com/viewformer/), [Geometry-biased Transformers for Novel View Synthesis](https://mayankgrwl97.github.io/gbt/), ECCV2024的[GGRt: Towards Pose-free Generalizable 3D Gaussian Splatting in Real-time](https://3d-aigc.github.io/GGRt/), [SparseGNV: Generating Novel Views of Indoor Scenes with Sparse Input Views](https://github.com/xt4d/SparseGNV), [HG3-NeRF: Hierarchical Geometric, Semantic, and Photometric Guided Neural Radiance Fields for Sparse View Inputs](https://arxiv.org/pdf/2401.11711), [CaesarNeRF: Calibrated Semantic Representation for Few-shot Generalizable Neural Rendering](https://haidongz-usc.github.io/project/caesarnerf), [HandNeRF: Learning to Reconstruct Hand-Object Interaction Scene from a Single RGB Image](https://samsunglabs.github.io/HandNeRF-project-page/), [Single-view Neural Radiance Fields with Depth Teacher](https://arxiv.org/pdf/2303.09952), ECCV2024的[NVS-Adapter: Plug-and-Play Novel View Synthesis from a Single Image](https://postech-cvlab.github.io/nvsadapter/), ECCV2024的[SparseCraft: Few-Shot Neural Reconstruction through Stereopsis Guided Geometric Linearization](https://sparsecraft.github.io/), ACM SIGGRAPH 2024的[A Construct-Optimize Approach to Sparse View Synthesis without Camera Pose](https://raymondjiangkw.github.io/cogs.github.io/), ECCV2024的[LaRa: Efficient Large-Baseline Radiance Fields](https://apchenstu.github.io/LaRa/), ACM SIGGRAPH ASIA 2023的[SinMPI: Novel View Synthesis from a Single Image with Expanded Multiplane Images](https://github.com/TrickyGo/SinMPI), [Sparse 3D Reconstruction via Object-Centric Ray Sampling](https://github.com/llukmancerkezi/ROSTER), [Harnessing Low-Frequency Neural Fields for Few-Shot View Synthesis](https://github.com/lsongx/halo), CVPR2023的[SCADE: NeRFs from Space Carving with Ambiguity-Aware Depth Estimates](https://scade-spacecarving-nerfs.github.io/), 
