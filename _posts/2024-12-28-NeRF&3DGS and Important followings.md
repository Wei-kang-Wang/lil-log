---
layout: post
comments: True
title: "NeRF&3DGS and Important followings"
date: 2024-12-28 01:09:00

---

<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---

[这里](https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics)是机器人领域的NeRF发展进程。

[这里](https://github.com/visonpon/New-View-Synthesis)是一个收藏了多个NeRF相关方法的github repo。

[这里](https://github.com/yangjiheng/nerf_and_beyond_docs)是另一个收藏了多个NeRF/3DGS相关方法的github repo。

ACM SIGGRAPH 2023的[3D Gaussian Splatting for Real-Time Radiance Field Rendering](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/), ECCV2020的[NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://github.com/yenchenlin/nerf-pytorch/tree/master), [这](https://github.com/bmild/nerf/tree/master)是另一个`pytorch`的NeRF实现。

ICCV2023的[FeatureNeRF: Learning Generalizable NeRFs by Distilling Foundation Models](https://jianglongye.com/featurenerf/), CVPR2022的[Deblur-NeRF: Neural Radiance Fields from Blurry Images](https://limacv.github.io/deblurnerf/), CVPR2024的[Is Vanilla MLP in Neural Radiance Field Enough for Few-shot View Synthesis?](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhu_Is_Vanilla_MLP_in_Neural_Radiance_Field_Enough_for_Few-shot_CVPR_2024_paper.pdf), CVPR2023 Highlights的[RobustNeRF: Ignoring Distractors with Robust Losses](https://robustnerf.github.io/), CVPR2024的[Free3D: Consistent Novel View Synthesis without 3D Representation](https://chuanxiaz.com/free3d/), CVPR2024 Oral的[EscherNet: A Generative Model for Scalable View Synthesis](https://kxhit.github.io/EscherNet), NeurIPS2023的[CorresNeRF: Image Correspondence Priors for Neural Radiance Fields](https://yxlao.github.io/corres-nerf/), ACM SIGGRAPH 2023的[Dictionary Fields: Learning a Neural Basis Decomposition](https://apchenstu.github.io/FactorFields/), CVPR2023的[DBARF: Deep Bundle-Adjusting Generalizable Neural Radiance Fields](https://aibluefisher.github.io/dbarf/), CVPR2022 Oral的[RegNeRF: Regularizing Neural Radiance Fields for View Synthesis from Sparse Inputs](https://m-niemeyer.github.io/regnerf/), CVPR2023 Highlights的[NoPe-NeRF: Optimising Neural Radiance Field with No Pose Prior](https://nope-nerf.active.vision/), ICCV2021 Oral的[BARF: Bundle-Adjusting Neural Radiance Fields](https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/), CVPR2023 Highlights的[SPARF: Neural Radiance Fields from Sparse and Noisy Poses](https://prunetruong.com/sparf.github.io/), CVPR2022的[Neural Rays for Occlusion-aware Image-based Rendering](https://liuyuan-pal.github.io/NeuRay/), CVPR2022 Oral的[Point-NeRF: Point-based Neural Radiance Fields](https://xharlie.github.io/projects/project_sites/pointnerf/), ICCV2023的[Forward Flow for Novel View Synthesis of Dynamic Scenes](https://npucvr.github.io/ForwardFlowDNeRF/), ICCV2023的[E2NeRF: Event Enhanced Neural Radiance Fields from Blurry Images](https://icvteam.github.io/E2NeRF.html), NeurIPS2021 Hightlight的[NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction](https://lingjie0206.github.io/papers/NeuS/), CVPR2023的[DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors](https://dogyoonlee.github.io/dpnerf/), ICCV2023的[Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction](https://lakonik.github.io/ssdnerf/), CVPR2022的[Learning Neural Light Fields with Ray-Space Embedding Networks](https://neural-light-fields.github.io/), CVPR2023的[3D Neural Field Generation using Triplane Diffusion](https://jryanshue.com/nfd/), CVPR2023的[K-Planes: Explicit Radiance Fields in Space, Time, and Appearance](https://sarafridov.github.io/K-Planes/), ECCV2022的[TAVA: Template-free Animatable Volumetric Actors](https://www.liruilong.cn/projects/tava/), CVPR2022的[HDR-NeRF: High Dynamic Range Neural Radiance Fields](https://xhuangcv.github.io/hdr-nerf/), ECCV2022的[BungeeNeRF: Progressive Neural Radiance Field for Extreme Multi-scale Scene Rendering](https://city-super.github.io/citynerf/), CVPR2022的[Deblur-NeRF: Neural Radiance Fields from Blurry Images](https://limacv.github.io/deblurnerf/), CVPR2022的[Ha-NeRF: Hallucinated Neural Radiance Fields in the Wild](https://rover-xingyu.github.io/Ha-NeRF/), ECCV2022的[ActiveNeRF: Learning where to See with Uncertainty Estimation](https://github.com/LeapLabTHU/ActiveNeRF), NeurIPS2023的[dynpoint: dynamic neural point for view synthesis](https://github.com/kaichen-z/DynPoint), CVPR2022的[NAN: Noise-Aware NeRFs for Burst-Denoising](https://noise-aware-nerf.github.io/), ACM SIGGRAPH 2023的[Factor Fields and Beyond](https://apchenstu.github.io/FactorFields/), ICCV2023的[ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces](https://wuqianyi.top/objectsdf++), NeurIPS2021 Spotlight的[NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction](https://lingjie0206.github.io/papers/NeuS/), ECCV2024的[MaRINeR: Enhancing Novel Views by Matching Rendered Images with Nearby References](https://boelukas.github.io/mariner/), ICCV2023的[HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion](https://ziyaerkoc.com/hyperdiffusion/), ACM SIGGRAPH 2024的[Binary Opacity Grids: Capturing Fine Geometric Detail for Mesh-Based View Synthesis](https://creiser.github.io/binary_opacity_grid/), ACM SIGGRAPH 2024的[2DGS: 2D Gaussian Splatting for Geometrically Accurate Radiance Fields](https://surfsplatting.github.io/), ECCV2024的[MVSGaussian: Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo](https://mvsgaussian.github.io/), [SpotLessSplats: Ignoring Distractors in 3D Gaussian Splatting](https://spolesssplats.github.io/), CVPR2023的[BAD-NeRF: Bundle Adjusted Deblur Neural Radiance Fields](https://wangpeng000.github.io/BAD-NeRF/), CVPR2024 Highlight的[Feature 3DGS: Supercharging 3D Gaussian Splatting to Enable Distilled Feature Fields](https://feature-3dgs.github.io/), [Deblurring 3D Gaussian Splatting](https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/), [NeuRodin: A Two-stage Framework for High-Fidelity Neural Surface Reconstruction](https://open3dvlab.github.io/NeuRodin/), [SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration](https://smerf-3d.github.io/), ACM SIGGRAPH ASIA 2023 Best Paper的[Adaptive Shells for Efficient Neural Radiance Field Rendering](https://research.nvidia.com/labs/toronto-ai/adaptive-shells/), CVPR2024 Highlight的[Gaussian Splatting SLAM](https://rmurai.co.uk/projects/GaussianSplattingSLAM/), [InstantSplat: Sparse-view SfM-free Gaussian Splatting in Seconds](https://instantsplat.github.io/), ACM SIGGRAPH 2024的[Bilateral Guided Radiance Field Processing](https://bilarfpro.github.io/), CVPR2024的[ReconFusion: 3D Reconstruction with Diffusion Priors](https://reconfusion.github.io/), [NVS-Solver: Video Diffusion Model as Zero-Shot Novel View Synthesizer](https://github.com/ZHU-Zhiyu/NVS_Solver), [A Decade's Battle on Dataset Bias: Are We There Yet?](https://github.com/liuzhuang13/bias)
