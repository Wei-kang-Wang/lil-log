---
layout: post
comments: True
title: "Video Generation"
date: 2024-12-28 01:09:00

---

<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---

## \[**NeurIPS 2020**\] [Unsupervised object-centric video generation and decomposition in 3D](https://www.pmh47.net/o3v/)

## \[**CVPR 2022**\] [Look Outside the Room: Synthesizing A Consistent Long-Term 3D Scene Video from A Single Image](https://xrenaa.github.io/look-outside-room/)

## \[**ICLR 2023**\] [Make-A-Video: Text-to-Video Generation without Text-Video Data](https://makeavideo.studio/)

## \[**ICCV 2023**\] [WALDO: Future Video Synthesis using Object Layer Decomposition and Parametric Flow Prediction](https://16lemoing.github.io/waldo/)

## \[**Arxiv 2024**\] [AtomoVideo: High Fidelity Image-to-Video Generation](https://atomo-video.github.io/)

## \[**ACM SIGGRAPH ASIA 2024**\] [LUMIERE: A Space-Time Diffusion Model for Video Generation](https://lumiere-video.github.io/)

## \[**ECCV Oral**\] [PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation](https://physdreamer.github.io/)

## [Photorealistic Video Generation with Diffusion Models](https://walt-video-diffusion.github.io/)

## [VideoBooth: Diffusion-based Video Generation with Image Prompts](https://vchitect.github.io/VideoBooth-project/)

## [VD3D: Taming Large Video Diffusion Transformers for 3D Camera Control](https://snap-research.github.io/vd3d/)

## [FreeInit : Bridging Initialization Gap in Video Diffusion Models](https://tianxingwu.github.io/pages/FreeInit/)
