---
layout: post
comments: True
title: "Single-view 3D Reconstruction"
date: 2024-12-28 01:09:00

---

<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---

## Single view 3D reconstruction with diffusion

[MVDream: Multi-view Diffusion for 3D Generation](https://mv-dream.github.io/), [DreamFusion: Text-to-3D using 2D Diffusion](https://github.com/ashawkey/stable-dreamfusion/tree/main), CVPR2024的[Splatter Image: Ultra-Fast Single-View
3D Reconstruction](https://szymanowiczs.github.io/splatter-image), ICLR2024 Spotlight的[SyncDreamer: Generating Multiview-consistent Images
from a Single-view Image](https://liuyuan-pal.github.io/SyncDreamer/), [Zero-1-to-3: Zero-shot One Image to 3D Object](https://zero123.cs.columbia.edu/), CVPR2024 Highlight的[Wonder3D: Single Image to 3D using Cross-Domain Diffusion](https://www.xxlong.site/Wonder3D/), ECCV2024的[HiFi-123: Towards High-fidelity One Image to 3D Content Generation](https://drexubery.github.io/HiFi-123/), CVPR2024的[MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation](https://mvd-fusion.github.io/), CVPR2024的[The More You See in 2D, the More You Perceive in 3D](https://sap3d.github.io/), ICCV2023的[Zero-1-to-3: Zero-shot One Image to 3D Object](https://zero123.cs.columbia.edu/), NeurIPS2023的[One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization](https://one-2-3-45.github.io/)


## Others

[AGG: Amortized Generative 3D Gaussians for Single Image to 3D](https://ir1d.github.io/AGG/), ECCV2022的[Towards High-Fidelity Single-view Holistic Reconstruction of Indoor Scenes](https://github.com/GAP-LAB-CUHK-SZ/InstPIFu?tab=readme-ov-file), CVPR2023的[Behind the Scenes: Density Fields for Single View Reconstruction](https://fwmb.github.io/bts/), ICCV2021 Oral的[Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image](https://infinite-nature.github.io/), CVPR2024的[Recon3D: High Quality 3D Reconstruction from a Single Image Using Generated Back-View Explicit Priors](https://openaccess.thecvf.com/content/CVPR2024W/NRI/papers/Chen_Recon3D_High_Quality_3D_Reconstruction_from_a_Single_Image_Using_CVPRW_2024_paper.pdf), ACM SIGGRAPH ASIA2023的[360° Reconstruction From a Single Image Using Space Carved Outpainting](https://cg.postech.ac.kr/research/POP3D/), ICCV2021的[PixelSynth: Generating a 3D-Consistent Experience from a Single Image](https://crockwell.github.io/pixelsynth/), [Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image](https://www.robots.ox.ac.uk/~vgg/research/flash3d/)

## Single view 3D reconstruction with NeRF/3DGS

[ConRad: Image Constrained Radiance Fields for 3D Generation from a Single Image](https://arxiv.org/pdf/2311.05230), [CCD-3DR: Consistent Conditioning in Diffusion for Single-Image 3D Reconstruction](https://arxiv.org/pdf/2308.07837), ECCV2022的[SinNeRF: Training Neural Radiance Fields on Complex Scenes from a Single Image](https://vita-group.github.io/SinNeRF/), CVPR2022的[Pix2NeRF: Unsupervised Conditional p-GAN for Single Image to Neural Radiance Fields Translation](https://github.com/primecai/Pix2NeRF), CVPR2022的[LOLNeRF: Learn from One Look](https://ubc-vision.github.io/lolnerf/), CVPR2024的[Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers](https://zouzx.github.io/TriplaneGaussian/), CVPR2023的[NeuralLift-360: Lifting An In-the-wild 2D Photo to A 3D Object with 360° Views](https://vita-group.github.io/NeuralLift-360/), 
