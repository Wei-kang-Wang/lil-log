---
layout: post
comments: True
title: "数据集"
date: 2024-09-22 01:09:00

---

<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---

## Human3.6m

数据集官网：http://vision.imar.ro/human3.6m/description.php

出自于论文[Human3. 6m: Large scale datasets and predictive methods for 3d human sensing in natural environments](https://ieeexplore.ieee.org/abstract/document/6682899)，是目前最大的人体姿态数据集，超过3.6 million张高清人体各种姿态的图片，这也是数据集名字的由来。

### 1. 数据集介绍

数据集由S1, S5, S6, S7, S8, S9, S11七个人的数据组成（有些博客说的是11个人，个人猜想是因为S2,S3,S4,S10因为某些原因没有被提供，因为从官网下载也只能下载到这七个人的数据），而每个人有15个动作：Directions, Discussion, Eating, Greetings, Phoning, Photo, Posing, Purchases, Sitting, SittingDown, Smoking, Waiting, WalkDog, Walking, WalkTogether。如下图所示（官网提供的下载）：

![1]({{ '/assets/images/h36m.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

human3.6m数据集下载整理之后的格式如下：s_09_act_08_subact_01_ca_04，其中s_09表示身份，有7个，act_08表示动作类别，有15个，subact_01有_01和_02两个，ca_04表示相机label，有4个。

> 注意，原始的数据里可能格式是Purchases 1.54138969或者Purchases.54138969，这里Purchases表示动作类别，1.以及 .表示subact，54138969是相机名字（相机名字有四个：54138969，55011271，58860488和60457274

部分标注数据格式如下：

```c
Human36M_subject*_data.json
|-- ‘images’: [
{‘id’: image id, 
‘file_name’: image file name, 
‘width’: image width, 
‘height’: image height, 
‘subject’: subject id, 
‘action_name’: action name, 
‘action_idx’: action id, 
‘subaction_idx’: subaction id, 
‘cam_idx’: camera id, 
‘frame_idx’: frame id
},
 ..., 
{same dict}
]
|-- ‘annotations’: [
{‘id’: annotation id,
‘image_id’: id of image where this annotations belongs to,
‘bbox’: bounding box (xmin, ymin, width, height)
},
…,
{same dict}
]

Human36M_subject*_camera.json
|-- camera id: {
‘R’: 3x3 rotation matrix (extrinsic parameter),
‘t’: 3-dimensional translation vector in milimeter (extrinsic parameter),
‘f’: 2-dimensional focal length (x- and y-axis) in pixel (intrinsic parameter),
‘c’: 2-dimensional principal point coordinates (x- and y-axis) in pixel (intrinsic parameter)
}

Human36M_subject*_joint_3d.json
|-- subject id
    |-- action id
        |-- subaction id
            |-- frame id: 17x3 joint coordinates in world coordinate system (not camera-centered coordinate system. you need to multiply camera extrinsic matrix to transform it to camera-centered coordinates) in milimeter.
```

> 注意原始标注数据里，会有D2_Positions, D3_Positions, D3_Positions_mono, D3_Positions_mono以及D3_Angles_mono的标注，其中D3_Positions是3D keypoints在world coordinate system下的坐标，所以其对于四个相机来说都是一样的，D3_Positions_mono是camera coordinate system下的坐标，其相当于D3_Positions城上rotation加上translation。D3_Positions_mono_universal复杂一点，其在D3_Positions_mono的基础上还乘上了一个scaling，使得尽管测试实体的每个人的身高大小有所不同，但D3_Positions_mono_universal都是一个尺度的，也就是两个人的D3_Positions_mono_universal的某个limb应该是差不多长的。
> 参考：(1) https://blog.csdn.net/weixin_50862344/article/details/128312265; (2) https://github.com/anibali/h36m-fetch/issues/13 (3) https://github.com/anibali/h36m-fetch/issues/16

尽管Human3.6m原数据集里关键点是32个点标注，但大多数情况下我们都使用17个点标注，如下图所示：

![2]({{ '/assets/images/h36m2.jpg' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}


### 2. 下载链接
该数据集需要申请才能使用，但从官网进行申请等待时间很长，而且不一定会通过，这个GitHub repo提供了一个方便的fetch：https://github.com/anibali/h36m-fetch/tree/master

以下提供一些非官方的该数据集的链接（**谨慎使用**）

1. 使用Human3.6m所属大学的外部公开数据库下载数据集

```python
  # Download H36M annotations
  mkdir data
  cd data
  wget http://visiondata.cis.upenn.edu/volumetric/h36m/h36m_annot.tar
  tar -xf h36m_annot.tar
  rm h36m_annot.tar

  # Download H36M images
  mkdir -p h36m/images
  cd h36m/images
  wget http://visiondata.cis.upenn.edu/volumetric/h36m/S1.tar
  tar -xf S1.tar
  rm S1.tar
  wget http://visiondata.cis.upenn.edu/volumetric/h36m/S5.tar
  tar -xf S5.tar
  rm S5.tar
  wget http://visiondata.cis.upenn.edu/volumetric/h36m/S6.tar
  tar -xf S6.tar
  rm S6.tar
  wget http://visiondata.cis.upenn.edu/volumetric/h36m/S7.tar
  tar -xf S7.tar
  rm S7.tar
  wget http://visiondata.cis.upenn.edu/volumetric/h36m/S8.tar
  tar -xf S8.tar
  rm S8.tar
  wget http://visiondata.cis.upenn.edu/volumetric/h36m/S9.tar
  tar -xf S9.tar
  rm S9.tar
  wget http://visiondata.cis.upenn.edu/volumetric/h36m/S11.tar
  tar -xf S11.tar
  rm S11.tar
  cd ../../..
```
  
2. 预处理过的每张图片大小为$$128 \times 128$$，带有坐标范围在$$0 \sim 1$$的2d joints标注的Human3.6m数据集

图片链接：https://drive.google.com/file/d/1dzuIWfNBxvIFHPdB7_JLiwALYNKeZHtV/view
标注链接：https://drive.google.com/file/d/1qud2X9L-vdVpD-JaWBakDx30-mx-2pkv/view

训练集是S1, S5, S6, S7, S8，测试集是S9和S11。

3. 一个提供了部分标注的Human3.6数据集

链接：https://drive.google.com/drive/folders/1r0B9I3XxIIW_jsXjYinDpL6NFcxTZart‘
描述：提供了图片尺寸，bounding box，camera内外参，以及$$17 \times 3$$的3d joints标注

4. Human3.6m的部分标注

链接：https://drive.google.com/drive/folders/112GPdRC9IEcwcJRyrLJeYw9_YV4wLdKC
描述：参考https://blog.csdn.net/stacey777/article/details/134734052和https://github.com/Vegetebird/MHFormer

5. 一些未经验证的链接

链接一：https://pan.baidu.com/s/1vFwNrN3PXiZzA4fwvw80-Q 提取码: 6prq
链接二：https://pan.baidu.com/s/10bDBP_Iw-5ylKMzJFfg1EQ 提取码: f664




